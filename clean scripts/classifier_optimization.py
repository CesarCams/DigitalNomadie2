import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import StandardScaler
from itertools import product
from tqdm import tqdm

#Selection of the model to encode the tweets ahead of training the classifier : 

#model_name = "sentence-transformers/all-MiniLM-L6-v2"
model_name = "vinai/bertweet-base" #This one gave the best results
#model_name = "distilbert-base-uncased"
#model_name = "cardiffnlp/twitter-roberta-base-sentiment"

#Selection of the classifier to use : 

#classifier_type = "LogisticRegression" 
#classifier_type = "LinearRegression"
classifier_type = "MLPClassifier" #This one gave the best results

model_id = model_name.split("/")[-1]
filename = "features_all_{}.npy".format(model_id)
features_np = np.load(filename)
features = torch.tensor(features_np, dtype=torch.float32)
filename_labels = "labels_all_{}.npy".format(model_id)
labels = np.load(filename_labels)
print("Embeddings generated by the model: ",model_name)

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


if classifier_type == "LogisticRegression":
    param_grid = {
        'C': [0.01,0.1, 1, 10,100,1000],  
        'penalty': ['l2'],  
    }

    logistic_model = LogisticRegression(max_iter=1000)

    grid_search = GridSearchCV(estimator=logistic_model, param_grid=param_grid, scoring='f1', cv=3, verbose=2, n_jobs=-1)

    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    print("Optimal parameters and results for logistic regression : ")
    print("Best Parameters: ", grid_search.best_params_)
    print("Test set F1 Score: ", f1)
    print("Test set accuracy : ", accuracy)

elif classifier_type == "LinearRegression":
    # Closed form solution, no grid search needed
    model = LinearRegression()
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    y_pred_labels = np.where(y_pred >= 0, 1, -1)

    accuracy = accuracy_score(y_test, y_pred_labels)
    f1 = f1_score(y_test, y_pred_labels)
    print("Results for linear regression : ")
    print("Test set F1 score:", f1)
    print("Test set accuracy:", accuracy)
    

elif classifier_type == "MLPClassifier":
    X_train = torch.tensor(X_train, dtype=torch.float32)
    X_test = torch.tensor(X_test, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.float32)
    y_test = torch.tensor(y_test, dtype=torch.float32)

    class MLP(nn.Module):
        def __init__(self, input_dim, hidden_dim, output_dim):
            super(MLP, self).__init__()
            self.model = nn.Sequential(
                nn.Linear(input_dim, hidden_dim),  # Couche cachée
                nn.ReLU(),  # Fonction d'activation ReLU
                nn.Linear(hidden_dim, output_dim),  # Couche de sortie
                nn.Sigmoid()  # Fonction d'activation pour la classification binaire
            )

        def forward(self, x):
            return self.model(x)

    # Hyperparamètres pour la Grid Search
    hidden_layer_sizes = [50, 100, 200]  # Tailles des couches cachées
    learning_rates = [0.00001, 0.001, 0.1]  # Taux d'apprentissage
    epoch_values = [100]  # Nombre d'époques

    # Initialiser le meilleur score et les meilleurs paramètres
    best_f1 = 0
    best_params = {}

    # Grid Search avec validation croisée
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    for hidden_dim, lr, epochs in product(hidden_layer_sizes, learning_rates, epoch_values):
        print(f"Testing configuration: Hidden Layer Size={hidden_dim}, Learning Rate={lr}, Epochs={epochs}")

        fold_f1_scores = []
        fold_acc_scores = []
        for fold, (train_idx, val_idx) in enumerate(kf.split(features)):
            print(f"Fold {fold + 1} / 5")

            # Diviser les données en ensemble d'entraînement et de validation
            X_train, X_val = features[train_idx], features[val_idx]
            y_train, y_val = labels[train_idx], labels[val_idx]

            # Convertir les données en tenseurs PyTorch
            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)
            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)
            y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)
            y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)

            # Initialiser le modèle, la fonction de perte et l'optimiseur
            input_dim = X_train.shape[1]
            output_dim = 1   # Sortie binaire (sigmoïde)

            model = MLP(input_dim, hidden_dim, output_dim).to(device)
            criterion = nn.BCELoss()  # Binary Cross-Entropy Loss
            optimizer = optim.Adam(model.parameters(), lr=lr)

            # Entraînement du modèle
            for epoch in tqdm(range(epochs), desc=f"Training Fold {fold + 1} (Hidden={hidden_dim}, LR={lr}, Epochs={epochs})", unit="epoch"):
                model.train()
                optimizer.zero_grad()

                # Prédiction et calcul de la perte
                outputs = model(X_train_tensor).squeeze()
                loss = criterion(outputs, (y_train_tensor + 1) / 2)  # Transformer -1/+1 en 0/1

                # Backpropagation et optimisation
                loss.backward()
                optimizer.step()

            # Évaluation du modèle sur l'ensemble de validation
            model.eval()
            with torch.no_grad():
                y_val_pred_proba = model(X_val_tensor).squeeze()
                y_val_pred = torch.where(y_val_pred_proba >= 0.5, 1.0, -1.0)  # Seuil à 0.5 pour binariser les prédictions

            # Conversion en NumPy pour sklearn
            y_val_np = y_val_tensor.cpu().numpy()
            y_val_pred_np = y_val_pred.cpu().numpy()

            # Calcul du F1-score pour ce pli
            fold_f1 = f1_score(y_val_np, y_val_pred_np)
            fold_acc = accuracy_score(y_val_np, y_val_pred_np)
            fold_f1_scores.append(fold_f1)
            fold_acc_scores.append(fold_acc)
        # Calcul du F1-score moyen pour les 5 plis
        mean_f1 = np.mean(fold_f1_scores)
        mean_acc = np.mean(fold_acc_scores)
        print(f"Configuration: Hidden={hidden_dim}, LR={lr}, Epochs={epochs} | Mean F1={mean_f1:.4f}")

        # Mise à jour des meilleurs paramètres
        if mean_f1 > best_f1:
            best_f1 = mean_f1
            acc = mean_acc
            best_params = {
                "hidden_dim": hidden_dim,
                "learning_rate": lr,
                "epochs": epochs
            }

    print("Optimal parameters and results for MLP classifier : ")
    print("Best Parameters:", best_params)
    print("Test set F1 Score:", best_f1)
    print("Test set accuracy:", acc)
else:
    print("Classifier not implemented. Please choose between 'LogisticRegression', 'LinearRegression' or 'MLPClassifier'")
    



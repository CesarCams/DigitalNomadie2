# Sentiment Analysis on Tweets

This project aims to predict the sentiment of tweets, specifically whether they express positive or negative sentiment, using machine learning and natural language processing (NLP) techniques. By leveraging pre-trained word embeddings and advanced language models, the goal is to classify tweets based on their sentiment while addressing the unique challenges posed by the informal and noisy nature of Twitter data.

## Workflow Overview

The project is organized into four main stages:

1. **Embedding Generation and Preprocessing**:
   - The `save_embeddings.py` script generates vector representations for tweets using models like GloVe, DistilBERT, and `all-MiniLM-L6-v2`. It transforms tweets into fixed-length feature vectors and saves them for model training.

2. **Model Training and Evaluation**:
   - The `classifier_optimization.py` script trains and evaluates machine learning models (e.g., logistic regression, support vector machines) on the generated embeddings to classify tweets as positive or negative. It also includes hyperparameter tuning for performance optimization.

3. **Fine-Tuning and Advanced Evaluation**:
   - The `fine_tuning.py` script fine-tunes the `twitter-roberta-base-sentiment` model, a pre-trained language model specialized for Twitter sentiment analysis. Fine-tuning enhances its performance for classifying sentiment in Twitter-specific text.

4. **Generate Submission File**:
   - The final script `run.py` generates predictions on the test dataset using the fine-tuned model and creates a `.csv` submission file compatible with evaluation platforms.

### Step 1: Generate tweets embeddings

The `save_embeddings.py` script is responsible for processing raw tweet data, extracting features using pre-trained embedding models, and saving the resulting feature matrices and labels. These embeddings serve as the input for training and evaluating classifiers in subsequent steps.

#### How the Script Works

Embedding Model Selection:
You can choose one of the following pre-trained models to generate embeddings:
- `sentence-transformers/all-MiniLM-L6-v2`
- `vinai/bertweet-base`
- `distilbert-base-uncased`
- `cardiffnlp/twitter-roberta-base-sentiment`

Depending on the selected model:
- sentence-transformers models are directly used via the SentenceTransformer library.
- Other models use Hugging Faceâ€™s AutoTokenizer and AutoModel.

Example:
model_name = "vinai/bertweet-base"  # Example model

1. **Load and Preprocess Data:**
   The script loads the tweet data from the following files:
   - train_neg_full.txt for negative tweets.
   - train_pos_full.txt for positive tweets.
   - test_data.txt for the submission testing data.

   Each tweet is labeled as 1 (positive) or -1 (negative).
   The data is shuffled to ensure randomness during training.


2. **DataFrame Preparation:**
   The tweets and their labels are stored in a pandas DataFrame.
   An additional feature, word_count, is added to capture the number of words in each tweet.


3. **Batch Encoding:**
   Tweets are processed in batches to manage memory usage effectively.
   Depending on the model:
   - For sentence-transformers, tweets are directly encoded using model.encode().
   - For other models, tokenization is performed using AutoTokenizer, and embeddings are extracted from the model's output.


4. **Combine Features:**
   The word count is added as an additional feature to the embeddings.
   The final feature matrix combines the embeddings and the word count.

Save Features and Labels:
The feature matrix and labels are saved as .npy files for use in the classifier training step.

#### How to Run the Script:
1. Select the embedding model by setting the model_name variable in the script.

2. Run the script:
   python save_embeddings.py

**Expected Output:**

1. A .npy file containing the feature matrix (embeddings with word count):
   features_all_<model_name>.npy

2. A .npy file containing the labels:
   labels_all_<model_name>.npy

Example Results:
Using the vinai/bertweet-base model, the script outputs:
- features_all_bertweet-base.npy: A matrix of tweet embeddings with additional word count features.
- labels_all_bertweet-base.npy: Labels corresponding to the sentiment of the tweets.

This step generates the necessary input for training classifiers, allowing you to experiment with various models and configurations in the subsequent steps.


### Step 2: Train and Evaluate the Model

The `classifier_optimization.py` script allows you to train and evaluate different classifiers using embeddings generated by a selected pre-trained model. You can choose the embedding model to use and the classifier to train, enabling a flexible and modular approach to sentiment classification.

Embedding Model Selection

Before training the classifier, the script lets you choose which embedding model's outputs to use. Options include:

- `sentence-transformers/all-MiniLM-L6-v2`
- `vinai/bertweet-base` (This provided the best results)
- `distilbert-base-uncased`
- `cardiffnlp/twitter-roberta-base-sentiment`

The embeddings are loaded from a `.npy` file generated in Step 1.

Classifier Selection

The script supports the following classifiers:

1. **Logistic Regression (Ridge):**
   - Performs grid search for optimal hyperparameters (regularization parameter).
   - Evaluates the best model on the test set using accuracy and F1 score.

2. **Linear Regression:**
   - Uses a closed-form solution without hyperparameter tuning.
   - Predictions are thresholded to classify sentiments.

3. **MLP Classifier (Multi-Layer Perceptron):**
   - Conducts a grid search for hidden layer size, learning rate, and epochs.
   - Trains the MLP using PyTorch and evaluates it on the test set.

#### How it Works

1. **Load and Normalize Data:**
   - Embeddings and labels are loaded from `.npy` files.
   - Embeddings are normalized using `StandardScaler`.

2. **Train the Classifier:**
   - Depending on the selected classifier, the script applies the appropriate training process:
     - Logistic Regression: Performs grid search using `GridSearchCV` to find the best hyperparameters and trains the model.
     - Linear Regression: Directly fits the model and thresholds the outputs for classification.
     - MLP Classifier: Implements a grid search for optimal configurations of hidden layer size, learning rate, and epochs.

3. **Evaluate the Model:**
   - Each classifier is evaluated on the test set using accuracy and F1 score.
   - The script outputs the best parameters and results for each classifier.

#### How to Run the Script

The classifier and embedding model can be selected directly in the script by modifying these variables:
model_name = "vinai/bertweet-base"  # Example embedding model
classifier = "MLPClassifier"       # Example classifier

Then, run the script:

python classifier_optimization.py

**Expected Output**

- Logistic Regression:
  - Outputs the best hyperparameters.
  - Prints test set F1 score and accuracy.
  
- Linear Regression:
  - Prints F1 score and accuracy directly after training.
  
- MLP Classifier:
  - Outputs the best parameters.
  - Prints test set F1 score and accuracy.

#### Example Results

For example, running the script with `vinai/bertweet-base` embeddings and the `MLPClassifier` might yield:
Optimal parameters and results for MLP classifier:
Best Parameters: {'hidden_dim': 100, 'learning_rate': 0.001}
Test set F1 Score: 0.87
Test set accuracy: 0.89

This modular design allows you to experiment with different combinations of embedding models and classifiers to find the best setup for your sentiment analysis task.

### Step 3: Fine-Tune the Pre-trained Model

The `fine_tuning.py` script is responsible for fine-tuning pre-trained language models on the tweet sentiment classification task. By leveraging transfer learning, this script adapts models like `vinai/bertweet-base` to the specific dataset, improving their performance on sentiment analysis for Twitter data.

#### How the Script Works

1. **Load Data**:
   - The script loads positive and negative tweets from the training files:
     - `train_pos_full.txt` for positive tweets.
     - `train_neg_full.txt` for negative tweets.
   - Labels are assigned as `1` for positive tweets and `-1` for negative tweets.
   - The data is shuffled and optionally downsampled to speed up the fine-tuning process.

2. **Device Configuration**:
   - The script automatically detects the device (e.g., GPU or CPU) to ensure optimal performance.
   - For Mac users, it supports the `mps` device for GPU acceleration.

3. **Model Selection**:
   - You can choose from various pre-trained models to fine-tune:
     - `sentence-transformers/all-MiniLM-L6-v2`
     - `vinai/bertweet-base` *(This provided the best results)*
     - `distilbert-base-uncased`
     - `cardiffnlp/twitter-roberta-base-sentiment`
   - The selected model and its tokenizer are loaded using the Hugging Face Transformers library.

4. **Tokenization**:
   - The tweets are tokenized to a fixed maximum length (128 tokens) with padding and truncation.
   - A Hugging Face `Dataset` is created, and the tokenized data is formatted for PyTorch.

5. **Train-Test Split**:
   - The dataset is split into training (80%) and evaluation (20%) sets to fine-tune the model and validate its performance.

6. **Training Arguments**:
   - The script uses Hugging Face's `TrainingArguments` to define the training configuration:
     - Number of epochs: 1
     - Batch size: 64 for both training and evaluation.
     - Warm-up steps: 500
     - Weight decay: 0.01
     - Logging and saving checkpoints during training.
   - The `mps` device is used for training if available (Mac-specific).

7. **Trainer Setup and Training**:
   - A Hugging Face `Trainer` object is created to manage the training process.
   - The model is trained on the training dataset with the defined configuration.

8. **Save Fine-Tuned Model**:
   - The fine-tuned model and its tokenizer are saved to a directory named `fine_tuned_<model_name>`.

9. **Evaluate the Model**:
   - After training, the model is evaluated on the evaluation dataset to obtain metrics like loss and accuracy.

Run the script:
python fine_tuning.py

The fine-tuned model and tokenizer will be saved in a directory named fine_tuned_<model_name>.

**Expected Output:**

The fine-tuned model and tokenizer are saved for future use:
./fine_tuned_bertweet-base

Evaluation results are printed to the console after training:
{'eval_loss': <value>, 'eval_accuracy': <value>}

This script demonstrates the effectiveness of transfer learning by fine-tuning a pre-trained model on a domain-specific task. It provides a strong foundation for sentiment analysis and other classification tasks on Twitter data.

### Step 4: Generate Submission File

This script is used to generate predictions on the test dataset using a fine-tuned model and create a submission file in the format required for evaluation.

#### How Script Works

1. **Load the Fine-Tuned Model and Tokenizer**:
   - The script loads the fine-tuned model and its corresponding tokenizer from the directory specified in `model_name`.
   - Example:
     ```
     model_name = "fine_tuned_bertweet-base"
     ```

2. **Load the Test Dataset**:
   - The script reads the test dataset from the `test_data.txt` file and processes each tweet for prediction.

3. **Predict Sentiment for Each Tweet**:
   - Each tweet is tokenized using the pre-trained tokenizer and passed to the fine-tuned model for inference.
   - The script computes the probabilities for positive and negative sentiments using the model's output logits and applies a softmax function to normalize them.
   - Based on the probabilities:
     - If the positive probability is higher, the tweet is labeled as `1` (positive).
     - Otherwise, it is labeled as `-1` (negative).

4. **Generate IDs for Tweets**:
   - Each tweet in the test dataset is assigned a unique ID starting from 1.

5. **Create Submission File**:
   - The script uses the `create_csv_submission` function (from the `helpers` module) to generate a `.csv` file with the tweet IDs and their corresponding predicted labels.
   - The submission file is saved with the name `submission_<model_name>.csv`, where `<model_name>` corresponds to the fine-tuned model's name.

#### How to Run the Script

1. Ensure the `model_name` variable points to the directory containing the fine-tuned model. For example:
model_name = "fine_tuned_bertweet-base"

2. Run the script:
python generate_submission.py

Expected Output:

A .csv file is created in the data/ directory. For example:
data/submission_bertweet-base.csv

The .csv file contains two columns:
- Id: The unique ID of each tweet.
- Prediction: The predicted sentiment label (1 for positive, -1 for negative).




